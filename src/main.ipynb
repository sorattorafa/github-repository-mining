{"cells":[{"cell_type":"code","execution_count":1,"source":[" pip install PyGithub pymongo requests bs4"],"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: PyGithub in /home/luiscapelari/.local/lib/python3.8/site-packages (1.55)\n","Requirement already satisfied: pymongo in /home/luiscapelari/.local/lib/python3.8/site-packages (3.11.4)\n","Requirement already satisfied: requests in /usr/lib/python3/dist-packages (2.22.0)\n","Requirement already satisfied: bs4 in /home/luiscapelari/.local/lib/python3.8/site-packages (0.0.1)\n","Requirement already satisfied: pynacl>=1.4.0 in /home/luiscapelari/.local/lib/python3.8/site-packages (from PyGithub) (1.4.0)\n","Requirement already satisfied: deprecated in /home/luiscapelari/.local/lib/python3.8/site-packages (from PyGithub) (1.2.12)\n","Requirement already satisfied: pyjwt>=2.0 in /home/luiscapelari/.local/lib/python3.8/site-packages (from PyGithub) (2.1.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/lib/python3/dist-packages (from bs4) (4.8.2)\n","Requirement already satisfied: cffi>=1.4.1 in /home/luiscapelari/.local/lib/python3.8/site-packages (from pynacl>=1.4.0->PyGithub) (1.14.5)\n","Requirement already satisfied: six in /usr/lib/python3/dist-packages (from pynacl>=1.4.0->PyGithub) (1.14.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /home/luiscapelari/.local/lib/python3.8/site-packages (from deprecated->PyGithub) (1.12.1)\n","Requirement already satisfied: pycparser in /home/luiscapelari/.local/lib/python3.8/site-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.20)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"metadata":{"scrolled":true,"trusted":true}},{"cell_type":"code","execution_count":2,"source":["import sys\n","import time\n","import requests\n","from datetime import datetime\n","# from dateutil import relativedelta\n","# from datetime import timedelta\n","import csv\n","import pymongo\n","import json\n","import os\n","import re\n","import pandas as pd\n","# from bs4 import BeautifulSoup\n","from collections import Counter"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["def get(url):\n","    attempts = 3\n","    attempt = 1\n","    while attempt <= attempts:\n","        try:\n","            response = requests.get(url)\n","            if response.status_code == 200:\n","                return response\n","            print(\"Not 200: {}\".format(url))\n","            return None\n","        except:\n","            print(\"Except: {}\".format(url))\n","\n","        attempt = attempt + 1\n","        sys.stdout.flush()\n","        time.sleep(3)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":4,"source":["# ACCESS_TOKEN = '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'\n","ACCESS_TOKEN = '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' #token L.O"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["def contain_test(filename):#, patch):\n","    test_regex = r\"((^|_| )(tests?)(_| |$))\"\n","    regex_compile = re.compile(test_regex)\n","    contain_in_name = regex_compile.findall(filename)\n","    # contain_in_patch = regex_compile.findall(patch)\n","\n","    if (contain_in_name):#  and contain_in_patch):\n","        return 1\n","    else:\n","        return 0"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["def prior_interaction(user, owner, name, time):\n","    url = 'https://api.github.com/repos/{}/{}/issues?access_token={}'.format(owner,name, ACCESS_TOKEN)\n","    data_all = get(url).json()\n","    count =0\n","    for data in data_all:\n","        date_pull =  datetime.fromisoformat(time[:len(time)-1]) \n","        date_interatction = data['created_at']\n","        date_interatction = datetime.fromisoformat(date_interatction[:len(date_interatction)-1])\n","        \n","        if ((data['user']['login'] == user) and (date_interatction < date_pull)):\n","            count+=1\n","    return count"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["def follow_manager(user, mergedBy):\n","    url = 'https://api.github.com/users/{}/following?access_token={}'.format(user, ACCESS_TOKEN)\n","  \n","    data_all = get(url).json()\n","    for data in data_all:\n","        if ((data['login'] == mergedBy)):\n","            return 1\n","    return 0"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["def user_followers_quantity(user):\n","    url = 'https://api.github.com/users/{}?&access_token={}'.format(user,ACCESS_TOKEN)\n","    data = get(url).json()\n","    followers_qty = data['followers']\n","    return followers_qty"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["def repo_collaborators_quantity():\n","    url = 'https://api.github.com/repos/{}/{}/pulls?state=closed&access_token={}'.format(owner, name, ACCESS_TOKEN)\n","    response = get(url).json()\n","\n","    colabrators = list()\n","    for data in response:\n","        if(data['merged_at']!=None):\n","            if(data['user']['login'] not in colabrators):\n","                colabrators.append(data['user']['login'])\n","\n","    return len(Counter(colabrators).keys())"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["def get_modified_files(owner, name, number):\n","    page = 1\n","    last_page = False\n","    files = []\n","    while not last_page:\n","        url = 'https://api.github.com/repos/{}/{}/pulls/{}/files?page={}&access_token={}'.format(owner, name, str(number), page, ACCESS_TOKEN)\n","        response = get(url)\n","        data_all = response.json()\n","        for data in data_all:\n","            file_infos = {}\n","            file_infos['changes'] = data['changes']\n","            # if 'patch' in data:\n","            #     file_infos['patch'] = data['patch']\n","            file_infos['contain_tests'] = contain_test(data['filename'])#,data['patch'])\n","           \n","            files.append(file_infos)\n","\n","        if 'Link' not in response.headers or 'rel=\"next\"' not in response.headers['Link']:\n","            last_page = True\n","        else:\n","            page = page + 1\n","\n","    return files"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["def modified_files_info(mofied_files):\n","    contain_test = 0\n","    changes_sum =0\n","    file_info_list = {}\n","    for i in mofied_files:\n","        changes_sum += i['changes']\n","        if(i['contain_tests']):\n","            contain_test = 1\n","    file_info_list['changes'] = changes_sum\n","    file_info_list['contain_tests'] = contain_test\n","    return file_info_list"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["def get_data(owner, name, number):\n","    url = 'https://api.github.com/repos/{}/{}/pulls/{}?access_token={}'.format(owner, name, str(number), ACCESS_TOKEN)\n","    data = get(url).json()\n","\n","    pull = {}\n","    pull['id']=number\n","    pull['user'] = data['user']['login']\n","    pull['comments'] = data['comments']\n","    pull['changed_files'] = data['changed_files']\n","    pull['merged'] = (1 if data['merged_at']!=None else 0)\n","\n","    collaborator_status = {\n","        'COLLABORATOR':1,\n","        'CONTRIBUTOR':0,\n","        'FIRST_TIMER':0,\n","        'FIRST_TIME_CONTRIBUTOR':0,\n","        'MANNEQUIN':0,\n","        'MEMBER':1,\n","        'NONE':0,\n","        'OWNER':1\n","    }\n","\n","    pull['collaborator_status'] = collaborator_status[data['author_association']]\n","    pull['user_prior_interaction'] = prior_interaction(data['user']['login'],owner,name,data['created_at'])\n","    if data['merged_by'] != None:\n","        pull['user_follow_manager'] = follow_manager(data['user']['login'], data['merged_by']['login'])\n","    else:\n","        pull['user_follow_manager'] = 0\n","    pull['user_followers_quantity'] = user_followers_quantity(data['user']['login'])\n","    modified_files = get_modified_files(owner, name, number)\n","    pull['files'] = modified_files_info(modified_files)\n","    \n","\n","    return pull"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["def collect_repo_infos(owner, name):\n","    url = 'https://api.github.com/repos/{}/{}?access_token={}'.format(owner, name, ACCESS_TOKEN)\n","    response = get(url)\n","    data = response.json()\n","    now = datetime.now()\n","\n","    repo = {}\n","    repo['is_fork'] = data['fork']\n","    repo['full_name'] = data['full_name']\n","    repo['stars'] = data['stargazers_count']\n","    repo['language'] = data['language']\n","    \n","    criado = data['created_at']\n","    criado = datetime.fromisoformat(criado[:len(criado)-1])\n","    \n","    repo['age'] = (now.year - criado.year) * 12 + (now.month - criado.month)\n","    repo['collaborators_quantity'] = repo_collaborators_quantity()\n","    return repo"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["def insert_pull_on_csv(dataset,pulldict):\n","    dataset = dataset.append({\n","        'project_name':pulldict['full_name'],\n","        'language':pulldict['language'],\n","        'age':pulldict['age'],\n","        'stars':pulldict['stars'],\n","        'contributors_count':pulldict['collaborators_quantity'],\n","        'submitter_login':pulldict['pull']['user'],\n","        'following_merger':pulldict['pull']['user_follow_manager'],\n","        'pull_request_id':pulldict['pull']['id'],\n","        'files_changed_count':pulldict['pull']['changed_files'],\n","        'changed_counts':pulldict['pull']['files']['changes'],\n","        'is_merged':pulldict['pull']['merged'],\n","        'pr_comments_count':pulldict['pull']['comments'],\n","        'test_is_included':pulldict['pull']['files']['contain_tests'],\n","        'followers_count':pulldict['pull']['user_followers_quantity'],\n","        'is_collaborator':pulldict['pull']['collaborator_status'],\n","        'prior_iterations_count':pulldict['pull']['user_prior_interaction']},\n","        ignore_index=True)\n","    return dataset"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":15,"source":["def collect_pulls(owner, name,dataset):\n","\n","    repo = collect_repo_infos(owner, name)\n","    # repo_id = repo['id']\n","    page = 1\n","    last_page = False\n","    # pulls = []\n","    while not last_page:\n","        #print('Page {}'.format(page))\n","        url = 'https://api.github.com/repos/{}/{}/pulls?state=closed&page={}&access_token={}'.format(owner, name, page, ACCESS_TOKEN)\n","        response = get(url)\n","        data_all = response.json()\n","        for data in data_all:\n","            pull = get_data(owner, name, data['number'])\n","            repo['pull'] = pull\n","            # pulls.append(repo) #adicionando primeiro informações do repositorio e depois informações do pull/informações extras\n","            #db.pulls.insert_one(pull)\n","            # print(pulls[len(pulls)-1], '\\n\\n\\n')\n","            # pull_to_json(repo, not last_page)\n","            dataset = insert_pull_on_csv(dataset,repo)\n","        if 'Link' not in response.headers or 'rel=\"next\"' not in response.headers['Link']:\n","            last_page = True\n","        else:\n","            page = page + 1\n","    return dataset"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":16,"source":["def convert_to_csv(dataset):\n","    dataset.to_csv('pulls.csv', index = None)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["#client = pymongo.MongoClient(\"localhost\", 27017)\n","#db = client.github_pulls\n","\n","if __name__ == '__main__':\n","    start = datetime.now()\n","    dataset = pd.DataFrame(columns=['project_name','language','age','stars','contributors_count','submitter_login','following_merger','pull_request_id',        'files_changed_count','changed_counts','is_merged','pr_comments_count','test_is_included','followers_count','is_collaborator','prior_iterations_count'])\n","\n","    projects_file = open('projects.csv', 'r')\n","    reader_projects = csv.reader(projects_file, delimiter=',')\n","    # init_json_file()\n","\n","    for row in reader_projects:\n","        owner = row[0]\n","        name = row[1]\n","\n","        print('Collecting... {} {}'.format(owner, __name__))\n","\n","        # pulls = \n","        dataset = collect_pulls(owner, name,dataset)\n","\n","    # finish_json_file()\n","        \n","    convert_to_csv(dataset)\n","    end = datetime.now()\n","    time = (end-start)\n","    print('Duração {} segundos',time.total_seconds())"],"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting... utfpr __main__\n","Duração {} segundos 198.184093\n"]}],"metadata":{"tags":[],"trusted":true}}],"metadata":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"metadata":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":5}